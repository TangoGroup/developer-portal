---
title: "Benchmarking"
description: "Defining and Setting the Bar for Human Flourishing"
---

# ğŸ“ Benchmarks and Standards at Gloo AI

Gloo AI is committed to building **transparent, value-aligned, and rigorous evaluation systems** for large language models. Our benchmarks are not just technicalâ€”they are human, faith-aware, and centered on real-world use in communities.

## âœ… What Weâ€™re Building

Weâ€™re developing a **shared benchmark framework** that is:

* **Open**: Designed to invite contribution from the wider faith-tech and AI ethics community
* **Collaborative**: Built alongside values-aligned partners, not just for internal use
* **Multidimensional**: Goes beyond accuracy to measure value alignment, relevance, and judgment

## ğŸ§  What We Evaluate

Each model is scored against a broad range of criteria across three primary dimensions:

1. **Objective** â€“ factual correctness, reasoning quality
2. **Subjective** â€“ tone, empathy, value alignment
3. **Tangential** â€“ off-topic drift, misunderstanding, or indirect errors

## ğŸ” Our Testing Approach

* **\~3,000+ curated evaluation prompts** mapped to 7 dimensions of human flourishing
* **Faith-specific QA** and worldview-sensitive questions sourced from real communities
* Evaluated by **LLMs and humans**, with checks for model self-awareness and consistency
* Support for **comparing open-source and proprietary models** side-by-side

We run evaluations across top models like Gemini, DeepSeek, Mistral, Grok, and others to identify strengths, failure modes, and opportunities for alignment.

## ğŸ“Š Results That Matter

Our benchmark results are designed to:

* **Inform partners** choosing models for high-trust environments
* **Guide internal training and fine-tuning** decisions
* **Track changes over time** as the AI landscape evolves
* Provide **transparent model performance reports** for trust-building

## ğŸ§° Tools You Can Use

Weâ€™re also building tools for:

* Automating model evaluation at scale
* Embedding benchmarks into CI/CD pipelines for ML
* Visualizing results across multiple dimensions and LLM types

<Info />

***

[Why Gloo AI?](/docs/why-gloo-ai)

[Our AI Models](/docs/our-llm)

* [Table of Contents](#)

* * [ğŸ“ Benchmarks and Standards at Gloo AI](#-benchmarks-and-standards-at-gloo-ai)

  * * [âœ… What Weâ€™re Building](#-what-were-building)
    * [ğŸ§  What We Evaluate](#-what-we-evaluate)
    * [ğŸ” Our Testing Approach](#-our-testing-approach)
    * [ğŸ“Š Results That Matter](#-results-that-matter)
    * [ğŸ§° Tools You Can Use](#-tools-you-can-use)
